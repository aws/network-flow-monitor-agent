#!/usr/bin/env python3

import json
import sys
import argparse
import datetime
from collections import defaultdict, Counter
from statistics import mean, median

def parse_timestamp(ts):
    """Convert timestamp in milliseconds to datetime object."""
    return datetime.datetime.fromtimestamp(ts / 1000.0)

class AgentReportAnalyzer:
    def __init__(self):
        self.report_attempts = []
        self.successful_reports = []
        self.failed_reports = []
        self.http_responses = []
        self.aggregation_stats = []
        self.first_timestamp = None
        self.last_timestamp = None
        self.total_lines = 0
        self.service_metadata = None
        
    def parse_log_file(self, file_path):
        """Parse the agent log file line by line."""
        print(f"Parsing log file: {file_path}")

        with open(file_path, 'r') as f:
            for line_number, line in enumerate(f, 1):
                self.total_lines += 1
                try:
                    log_entry = json.loads(line)
                    
                    # Extract timestamp
                    timestamp = log_entry.get('timestamp')
                    if timestamp:
                        if self.first_timestamp is None:
                            self.first_timestamp = timestamp
                        self.last_timestamp = timestamp

                    # Detect service metadata
                    if "service_metadata" in log_entry:
                        self.service_metadata = log_entry.get("service_metadata")
                        
                    # Track report attempts and HTTP responses
                    if log_entry.get('message') == 'Publishing report':
                        self.report_attempts.append({
                            'timestamp': timestamp,
                            'datetime': parse_timestamp(timestamp),
                        })
                        
                    if log_entry.get('message') == 'HTTP request complete':
                        status = log_entry.get('status')
                        self.http_responses.append({
                            'timestamp': timestamp, 
                            'status': status
                        })
                        
                        if status == 200:
                            self.successful_reports.append(timestamp)
                        else:
                            self.failed_reports.append(timestamp)
                            
                except json.JSONDecodeError:
                    print(f"Error parsing line {line_number}")

    def generate_summary(self):
        """Generate a basic summary of findings."""
        duration_sec = (self.last_timestamp - self.first_timestamp) / 1000.0 if self.first_timestamp and self.last_timestamp else 0
        
        # Extract agent metadata
        agent_info = {}
        if self.service_metadata:
            agent_info = {
                "name": self.service_metadata.get("name", {}).get("String", "Unknown"),
                "version": self.service_metadata.get("version", {}).get("String", "Unknown"),
            }
        
        # Calculate publication intervals
        intervals = []
        for i in range(1, len(self.report_attempts)):
            curr = self.report_attempts[i]['timestamp']
            prev = self.report_attempts[i-1]['timestamp']
            interval_sec = (curr - prev) / 1000.0
            intervals.append(interval_sec)
            
        # Count HTTP status codes
        status_counts = Counter(resp['status'] for resp in self.http_responses)
        
        summary = {
            'agent_info': agent_info,
            'log_overview': {
                'total_lines': self.total_lines,
                'duration_minutes': duration_sec / 60
            },
            'report_statistics': {
                'attempts': len(self.report_attempts),
                'successful': len(self.successful_reports),
                'failed': len(self.failed_reports),
                'success_rate': (len(self.successful_reports) / len(self.report_attempts) * 100) if self.report_attempts else 0,
                'avg_interval_sec': mean(intervals) if intervals else 0
            },
            'http_status_counts': status_counts
        }
        return summary

def main():
    parser = argparse.ArgumentParser(description='Analyze NFM Agent log files (simplified version).')
    parser.add_argument('log_file', type=str, help='Path to the agent log file')
    parser.add_argument('--json', action='store_true', help='Output summary as JSON')
    args = parser.parse_args()
    
    analyzer = AgentReportAnalyzer()
    analyzer.parse_log_file(args.log_file)
    
    summary = analyzer.generate_summary()
    print(json.dumps(summary, indent=2, default=str))

if __name__ == "__main__":
    main()
